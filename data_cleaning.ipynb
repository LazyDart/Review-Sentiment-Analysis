{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Eventual Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Text Processing\n",
    "import emoji\n",
    "import re\n",
    "import string\n",
    "\n",
    "# NLP\n",
    "import spacy\n",
    "\n",
    "# Spell Checking\n",
    "import enchant\n",
    "from autocorrect import Speller\n",
    "from enchant.checker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready scraped data\n",
    "df = pd.read_csv(\"./data/merged_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_date</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>full_category</th>\n",
       "      <th>offer_ref</th>\n",
       "      <th>product_title</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>score</th>\n",
       "      <th>top_category</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-17 21:55:15</td>\n",
       "      <td>13788058</td>\n",
       "      <td>Sport i rekreacja/Sporty zimowe/Sanki i lizga...</td>\n",
       "      <td>83158301</td>\n",
       "      <td>Springos Drewniane Z Oparciem SAN001</td>\n",
       "      <td>2021-01-11 13:35:10</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sanki</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-17 21:55:15</td>\n",
       "      <td>15442912</td>\n",
       "      <td>Sport i rekreacja/Sporty zimowe/Sanki i lizga...</td>\n",
       "      <td>83158301</td>\n",
       "      <td>Springos Drewniane Z Oparciem SAN001</td>\n",
       "      <td>2021-01-11 13:35:10</td>\n",
       "      <td>Lekkie i jak jeste na kuligu to szypko spadas...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Sanki</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-06 21:25:40</td>\n",
       "      <td>18181118</td>\n",
       "      <td>Sport i rekreacja/Sporty zimowe/Sanki i lizga...</td>\n",
       "      <td>123702927</td>\n",
       "      <td>lizgacz sanki dmuchane na nieg koo opona</td>\n",
       "      <td>2023-11-30 21:30:26</td>\n",
       "      <td>Niestety, zamiast opony otrzymaam pingwina,wi...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>lizgacze</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-14 16:24:28</td>\n",
       "      <td>11430370</td>\n",
       "      <td>Sport i rekreacja/Sporty zimowe/Sanki i lizga...</td>\n",
       "      <td>83158301</td>\n",
       "      <td>Springos Drewniane Z Oparciem SAN001</td>\n",
       "      <td>2019-12-03 19:41:18</td>\n",
       "      <td>Mogy by estetyczniej wykonane.</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Sanki</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-15 09:33:06</td>\n",
       "      <td>18213380</td>\n",
       "      <td>Sport i rekreacja/Sporty zimowe/Sanki i lizga...</td>\n",
       "      <td>123702927</td>\n",
       "      <td>lizgacz sanki dmuchane na nieg koo opona</td>\n",
       "      <td>2023-12-11 14:15:39</td>\n",
       "      <td>Bardzo dobry</td>\n",
       "      <td>5.0</td>\n",
       "      <td>lizgacze</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178786</th>\n",
       "      <td>2014-06-24 12:33:23</td>\n",
       "      <td>3083673</td>\n",
       "      <td>Uroda/Perfumy i wody/Zapachy damskie/Perfumy i...</td>\n",
       "      <td>39052947</td>\n",
       "      <td>Calvin Klein Euphoria Woda Perfumowana 100 ml</td>\n",
       "      <td>2014-06-09 18:17:17</td>\n",
       "      <td>produkt orginalny</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Perfumy i wody damskie</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178787</th>\n",
       "      <td>2014-06-24 12:33:23</td>\n",
       "      <td>3118716</td>\n",
       "      <td>Uroda/Perfumy i wody/Zapachy damskie/Perfumy i...</td>\n",
       "      <td>39052947</td>\n",
       "      <td>Calvin Klein Euphoria Woda Perfumowana 100 ml</td>\n",
       "      <td>2014-06-09 18:17:17</td>\n",
       "      <td>Nie wiem czy to wina reformacji zapachu czy mo...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Perfumy i wody damskie</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179362</th>\n",
       "      <td>2013-06-25 14:02:34</td>\n",
       "      <td>10510760</td>\n",
       "      <td>Uroda/Perfumy i wody/Zapachy damskie/Perfumy i...</td>\n",
       "      <td>25152710</td>\n",
       "      <td>Hugo Boss Nuit Pour Femme Woda Perfumowana 75 ml</td>\n",
       "      <td>2014-02-24 13:26:16</td>\n",
       "      <td>Polecam ten zapach gdy偶 jest lekki do pomieszc...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Perfumy i wody damskie</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180034</th>\n",
       "      <td>2021-04-04 13:47:49</td>\n",
       "      <td>14630530</td>\n",
       "      <td>Uroda/Perfumy i wody/Zapachy mskie/Perfumy i ...</td>\n",
       "      <td>39817736</td>\n",
       "      <td>Christian Dior Sauvage Woda Toaletowa 100 ml</td>\n",
       "      <td>2021-03-17 13:02:54</td>\n",
       "      <td>Zapach jest nietrway. Zamawiaam wczeniej 10...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Perfumy i wody mskie</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180096</th>\n",
       "      <td>2011-09-14 09:43:49</td>\n",
       "      <td>1863820</td>\n",
       "      <td>Hobby i zwierzta/Karmy i akcesoria dla ps贸w/K...</td>\n",
       "      <td>14411821</td>\n",
       "      <td>Brit Care Junior Large Breed Lamb&amp;Rice 3Kg</td>\n",
       "      <td>2011-10-04 09:13:07</td>\n",
       "      <td>Bardzo dobra karma. Pies chtnie j je. Sier...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Suche</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65012 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_date  entry_id   \n",
       "0      2021-01-17 21:55:15  13788058  \\\n",
       "1      2021-01-17 21:55:15  15442912   \n",
       "2      2023-12-06 21:25:40  18181118   \n",
       "3      2019-12-14 16:24:28  11430370   \n",
       "4      2023-12-15 09:33:06  18213380   \n",
       "...                    ...       ...   \n",
       "178786 2014-06-24 12:33:23   3083673   \n",
       "178787 2014-06-24 12:33:23   3118716   \n",
       "179362 2013-06-25 14:02:34  10510760   \n",
       "180034 2021-04-04 13:47:49  14630530   \n",
       "180096 2011-09-14 09:43:49   1863820   \n",
       "\n",
       "                                            full_category  offer_ref   \n",
       "0       Sport i rekreacja/Sporty zimowe/Sanki i lizga...   83158301  \\\n",
       "1       Sport i rekreacja/Sporty zimowe/Sanki i lizga...   83158301   \n",
       "2       Sport i rekreacja/Sporty zimowe/Sanki i lizga...  123702927   \n",
       "3       Sport i rekreacja/Sporty zimowe/Sanki i lizga...   83158301   \n",
       "4       Sport i rekreacja/Sporty zimowe/Sanki i lizga...  123702927   \n",
       "...                                                   ...        ...   \n",
       "178786  Uroda/Perfumy i wody/Zapachy damskie/Perfumy i...   39052947   \n",
       "178787  Uroda/Perfumy i wody/Zapachy damskie/Perfumy i...   39052947   \n",
       "179362  Uroda/Perfumy i wody/Zapachy damskie/Perfumy i...   25152710   \n",
       "180034  Uroda/Perfumy i wody/Zapachy mskie/Perfumy i ...   39817736   \n",
       "180096  Hobby i zwierzta/Karmy i akcesoria dla ps贸w/K...   14411821   \n",
       "\n",
       "                                           product_title       purchase_date   \n",
       "0                   Springos Drewniane Z Oparciem SAN001 2021-01-11 13:35:10  \\\n",
       "1                   Springos Drewniane Z Oparciem SAN001 2021-01-11 13:35:10   \n",
       "2            lizgacz sanki dmuchane na nieg koo opona 2023-11-30 21:30:26   \n",
       "3                   Springos Drewniane Z Oparciem SAN001 2019-12-03 19:41:18   \n",
       "4            lizgacz sanki dmuchane na nieg koo opona 2023-12-11 14:15:39   \n",
       "...                                                  ...                 ...   \n",
       "178786     Calvin Klein Euphoria Woda Perfumowana 100 ml 2014-06-09 18:17:17   \n",
       "178787     Calvin Klein Euphoria Woda Perfumowana 100 ml 2014-06-09 18:17:17   \n",
       "179362  Hugo Boss Nuit Pour Femme Woda Perfumowana 75 ml 2014-02-24 13:26:16   \n",
       "180034      Christian Dior Sauvage Woda Toaletowa 100 ml 2021-03-17 13:02:54   \n",
       "180096        Brit Care Junior Large Breed Lamb&Rice 3Kg 2011-10-04 09:13:07   \n",
       "\n",
       "                                              review_text  score   \n",
       "0                                                          1.0  \\\n",
       "1       Lekkie i jak jeste na kuligu to szypko spadas...    1.5   \n",
       "2       Niestety, zamiast opony otrzymaam pingwina,wi...    1.5   \n",
       "3                        Mogy by estetyczniej wykonane.    3.5   \n",
       "4                                            Bardzo dobry    5.0   \n",
       "...                                                   ...    ...   \n",
       "178786                                  produkt orginalny    3.5   \n",
       "178787  Nie wiem czy to wina reformacji zapachu czy mo...    3.5   \n",
       "179362  Polecam ten zapach gdy偶 jest lekki do pomieszc...    3.5   \n",
       "180034  Zapach jest nietrway. Zamawiaam wczeniej 10...    1.5   \n",
       "180096  Bardzo dobra karma. Pies chtnie j je. Sier...    5.0   \n",
       "\n",
       "                  top_category sentiment  \n",
       "0                        Sanki  Negative  \n",
       "1                        Sanki  Negative  \n",
       "2                    lizgacze  Negative  \n",
       "3                        Sanki   Neutral  \n",
       "4                    lizgacze  Positive  \n",
       "...                        ...       ...  \n",
       "178786  Perfumy i wody damskie   Neutral  \n",
       "178787  Perfumy i wody damskie   Neutral  \n",
       "179362  Perfumy i wody damskie   Neutral  \n",
       "180034   Perfumy i wody mskie  Negative  \n",
       "180096                   Suche  Positive  \n",
       "\n",
       "[65012 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete reviews written in cyrillic with a mix of polish characters (Those cases are not handled by cyryllic fix later on)\n",
    "df = df[~(df[\"offer_ref\"].isin([119352308, 126556830, 97049775,]) \n",
    "          & df[\"entry_id\"].isin([16919388, 16453304, 16368349,]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"review_text\" nan are to be deleted. Other can stay.\n",
    "df = df.dropna(subset=[\"review_text\"])\n",
    "\n",
    "# Remove invalid entries\n",
    "df = df.loc[df[\"entry_date\"] != \"entry_date\"]\n",
    "\n",
    "# Remove duplicate entries\n",
    "df = df.drop_duplicates([\"offer_ref\", \"entry_id\", \"review_text\"]).drop_duplicates(\"review_text\")\n",
    "\n",
    "# fix data types\n",
    "df[\"entry_date\"] = pd.to_datetime(df[\"entry_date\"])\n",
    "df[\"purchase_date\"] = pd.to_datetime(df[\"purchase_date\"])\n",
    "df[\"entry_id\"] = df[\"entry_id\"].astype(int)\n",
    "df[\"offer_ref\"] = df[\"offer_ref\"].astype(int)\n",
    "df[\"score\"] = df[\"score\"].astype(float)\n",
    "\n",
    "# Get Sentiment Cases based on score\n",
    "df[\"sentiment\"] = df[\"score\"].apply(lambda x: \"Positive\" if x >= 4 else \"Negative\" if x <= 2 else \"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only text and sentiment\n",
    "to_clean = df[[\"review_text\", \"sentiment\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of newlines and other whitespace chars\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].replace(\"[\\t\\r\\n\\v\\f\\ufeff]\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_text, sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove whitespaces created by previous step\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].replace(\" +\", \" \", regex=True)\n",
    "to_clean[to_clean[\"review_text\"].str.contains(\"  \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove cyrillic characters. Sometimes there are reviews half written in cyrillic and half in polish, so I will keep polish characters.\n",
    "cyrylic_regex = f\"[ {string.punctuation}0-9]*[\\u0400-\\u04FF]+[ {string.punctuation}0-9]*[\\u0400-\\u04FF]+[ {string.punctuation}0-9]*\"\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(lambda x: re.sub(cyrylic_regex, \"\", x)).replace(\"\", np.nan)\n",
    "to_clean = to_clean.dropna(subset=[\"review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark all emojis in data. All_emoji will be excluded entirely, and has_emoji will remove only emojis.\n",
    "to_clean[\"has_emoji\"] = to_clean[\"review_text\"].transform(lambda x: np.any([emoji.is_emoji(c) for c in x]))\n",
    "to_clean[\"all_emoji\"] = to_clean[\"review_text\"].transform(lambda x: np.all([emoji.is_emoji(c) for c in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "# 460 Reviews containing emojis\n",
    "print(len(to_clean[to_clean[\"has_emoji\"]]))\n",
    "# 42 reviews containing only emojis\n",
    "print(len(to_clean[to_clean[\"all_emoji\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>all_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td></td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9421</th>\n",
       "      <td></td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053</th>\n",
       "      <td></td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td></td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11179</th>\n",
       "      <td>コ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13728</th>\n",
       "      <td>火</td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14711</th>\n",
       "      <td></td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24204</th>\n",
       "      <td></td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25324</th>\n",
       "      <td></td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_text sentiment  has_emoji  all_emoji\n",
       "0                Negative       True       True\n",
       "1091              Negative       True       True\n",
       "9421               Neutral       True       True\n",
       "10053         Positive       True       True\n",
       "10958             Positive       True       True\n",
       "11179          コ  Positive       True       True\n",
       "13728        火  Negative       True       True\n",
       "14711             Neutral       True       True\n",
       "24204             Positive       True       True\n",
       "25324             Negative       True       True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can sort of guess the sentiment of the review based on the emojis. But it's not consistent.\n",
    "to_clean[to_clean[\"all_emoji\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>all_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_text, sentiment, has_emoji, all_emoji]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1927 reviews containing special unicode characters\n",
    "to_clean[to_clean[\"review_text\"].str.contains(\"[\\t\\r\\n\\v\\f\\ufeff]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark Ok's in data.\n",
    "to_clean[\"has_ok\"] = to_clean[\"review_text\"].str.lower().str.contains(\"\\Wok\\W\")\n",
    "to_clean[to_clean[\"has_ok\"]] = to_clean[to_clean[\"has_ok\"]].replace(r\"\\bok\\b\", \"Ok\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kupiem za namow ssiad贸w, kt贸rzy zachwycali si mo偶liwoci pieczenia 2 potraw jednoczenie. Dual Cooki nie s drogie, miaem Ok. 2000 z na piekarnik (poprzedni zepsu si po 13 latach, ale wiem, 偶e takich urzdze ju偶 nie ma...). Zdecydowaem si na ten model cho ju偶 w sklepie pojawiy si pierwsze wtpliwoci... drzwiczki piekarnika trzaskaj jak w maluchu, obudowa drzwi jest w peni plastikowa i nie znalazem 偶adnego uszczelnienie tej przegrody rozdzielajcej piekarnik na 2 czci. Sprzedawca stwierdzi, 偶e s to bzdety nie majce wpywu na jako pieczenia i szczerze m贸wic przekona mnie. Piek g贸wnie misiwa, a 偶ona ciasta - piekarnik dziaa praktycznie codziennie, u偶ywamy go tak偶e do podgrzewania (nie lubi mikrofali). Rozczarowanie przyszo ju偶 po pierwszym pieczeniu - piekarnik bardzo dugo si nagrzewa - temperatur 220 stopni osign po 20 minutach, mimo, 偶e termostat pokazywa tak temperatur ju偶 po 8-10 minutach - wasny termometr pokaza, 偶e piekarnik przekamuje... Potrawa upieka si r贸wnomiernie, ale stanowczo za dugo to trwao. Trzaskajce drzwi piekarnika doprowadzaj mnie do szau - po co producent zamontowa 2 gumki amortyzujce, skoro s za kr贸tkie? Na dodatek w moim starym piekarniku drzwi domykay si delikatnie, wyhamowujc pod koniec. Plastikowo piekarnika faktycznie nie ma wpywu na u偶ytkowanie. Kolejnym rozczarowaniem jest ta granatowa emalia ceramiczna - strasznie trudno j doczyci. Przy kolejnym pieczeniu zorientowaem si, 偶e ten piekarnik ma tylko 4 poziomy, a nie jak m贸j poprzedni 5! Na dodatek rozmieszczenie poziom贸w przy pieczeniu dual cook nie pozwala na zmieszczenie w dolnej czci niczego co nie jest paskie, a w g贸rnej nie mieci si brytfanna z maym wiejskim kurczakiem... Przegrod po prostu wyjem z piekarnika - wychodzi na to, 偶e dual cook to ciema marketingowa. Na dodatek korzystajc z komory g贸rnej mamy tylko grzak g贸rn i termoobieg - brak grzaki dolnej - w przypadku dolnej komory nie mamy grzaki g贸rnej i grilla - totalnie bez sensu. Kolejny problem pojawi si przy pieczeniu z par (blacha z wod pod misem) - uszczelka przecieka i woda skrapla si po szafce... W zwizku z powy偶szym sprzedaem piekarnik po miesicu za poow ceny na znanym portalu aukcyjnym i kupiem co normalnego od polskiego producenta za 1300 z - piekarnik nagrzewa si do 220 stopni w 8 minut i nie przecieka przy pieczeniu na parze, no i ma delikatny domyk drzwi. Nigdy wicej badziewia Samsunga - tak jak przejechaem si na 2 flagowych telefonach tej marki i tanim tv, tak teraz jeszcze na piekarniku! AGD tej firmy to tragedia!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_clean[to_clean[\"has_ok\"] & (to_clean[\"sentiment\"] != \"Positive\")][\"review_text\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>all_emoji</th>\n",
       "      <th>has_ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_text, sentiment, has_emoji, all_emoji, has_ok]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix_ok_in_string assumes that ok. (circa) happens once per review. We can safely assume that.\n",
    "to_clean[to_clean[\"review_text\"].transform(lambda x: len(re.findall(r\"\\bok\\b.? [0-9]+\", x))) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function discriminates between ok meaning good and ok meaning circa \n",
    "# which is a short form of okoo in polish language.\n",
    "# Ok has it's own fix because it is very common in reviews and gives positive sentiment.\n",
    "def fix_ok_in_string(text):\n",
    "    circa_match = re.search(r\"\\bok\\b.? [0-9]+\", text.lower())\n",
    "    if circa_match is not None:\n",
    "        circa_match = circa_match.span()\n",
    "        return re.sub(r\"\\b(ok|Ok|OK|oK)\\b\", \"Ok\", text[:circa_match[0]]) + text[circa_match[0]:circa_match[1]] + re.sub(r\"\\b(ok|Ok|OK|oK)\\b\", \"Ok\", text[circa_match[1]:])\n",
    "    else:\n",
    "        return re.sub(r\"\\b(ok|Ok|OK|oK)\\b\", \"Ok\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok. lalala ok. 100kg Ok!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_ok_in_string(\"ok. lalala ok. 100kg ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all ok's in data.\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(fix_ok_in_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all numbers from data.\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(lambda x: re.sub(\"[0-9]+\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Largest default polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Autocorrect speller\n",
    "spell = Speller(\"pl\", only_replacements=True)\n",
    "\n",
    "# Enchant spellcheckers\n",
    "chkr = SpellChecker(\"pl_Pl\") \n",
    "d_typo = enchant.Dict(\"pl_PL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(lambda x: nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean[\"Typo Data\"] = (\n",
    "    to_clean[\"review_text\"].transform(lambda x: \n",
    "        [[token.text, \n",
    "          d_typo.suggest(token.text), \n",
    "          i, \n",
    "          str(x).find(token.text), \n",
    "          len(token.text)] \n",
    "        for i, token in enumerate(x) \n",
    "            if not token.is_punct \n",
    "               and (not d_typo.check(token.text)) \n",
    "               and (emoji.is_emoji(token.text) == False)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean.to_pickle(\"./data/typos_annotated.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will run 3 mins\n",
    "\n",
    "# Get subset of data.\n",
    "checker_test = to_clean[\"review_text\"].iloc[:2000].transform(lambda x: nlp(x))\n",
    "\n",
    "# 42% of first 2000 reviews contain typos\n",
    "# pyenchany seems good at detecting typos however it seems bad at fixing typos So we'll have to be careful with it.\n",
    "checker_test[checker_test.transform(lambda x: all([d_typo.check(token.text.lower()) for token in x if not token.is_punct])) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Mins. tokenize data\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes 44 mins.\n",
    "## Fix all typos. Write 2 csv files with and without type fixing. Used for comparison in another script.\n",
    "to_clean[\"review_text\"].transform(lambda x: [d_typo.suggest(token.text)[0] if (not token.is_punct) and (not d_typo.check(token.text)) and (chkr.suggest(token.text))  else token for token in x]).to_csv(\"Testing Typo Checking.csv\")\n",
    "to_clean[\"review_text\"].to_csv(\"Comparison to a Typo fix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've forgotten about sentiment.\n",
    "to_clean[\"sentiment\"].to_csv(\"sentiment provision.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
