{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Eventual Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Text Processing\n",
    "import emoji\n",
    "import re\n",
    "import string\n",
    "\n",
    "# NLP\n",
    "import spacy\n",
    "\n",
    "# Language Detection\n",
    "from transformers import pipeline\n",
    "\n",
    "# Spell Checking\n",
    "import enchant\n",
    "from autocorrect import Speller\n",
    "from enchant.checker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready scraped data\n",
    "df = pd.read_csv(\"./data/merged_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: review_text, dtype: object)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df[\"offer_ref\"].isin([119352308, 126556830, 97049775,]) \n",
    "        & df[\"entry_id\"].isin([16919388, 16453304, 16368349,])),\n",
    "        \"review_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete reviews written in cyrillic with a mix of polish characters (Those cases are not handled by cyryllic fix later on)\n",
    "df = df[~(df[\"offer_ref\"].isin([119352308, 126556830, 97049775,]) \n",
    "          & df[\"entry_id\"].isin([16919388, 16453304, 16368349,]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_langs = pd.read_csv(\"./data/foreign_languages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: review_text, dtype: object)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"entry_id\"].isin(other_langs[\"entry_id\"]) \n",
    "       & df[\"offer_ref\"].isin(other_langs[\"offer_ref\"]), \n",
    "       \"review_text\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete reviews written in other languages\n",
    "df = df.loc[~(df[\"entry_id\"].isin(other_langs[\"entry_id\"]) \n",
    "              & df[\"offer_ref\"].isin(other_langs[\"offer_ref\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"review_text\" nan are to be deleted. Other can stay.\n",
    "df = df.dropna(subset=[\"review_text\"])\n",
    "\n",
    "# Remove invalid entries\n",
    "df = df.loc[df[\"entry_date\"] != \"entry_date\"]\n",
    "\n",
    "# Remove duplicate entries\n",
    "df = df.drop_duplicates([\"offer_ref\", \"entry_id\", \"review_text\"]).drop_duplicates(\"review_text\")\n",
    "\n",
    "# fix data types\n",
    "df[\"entry_date\"] = pd.to_datetime(df[\"entry_date\"])\n",
    "df[\"purchase_date\"] = pd.to_datetime(df[\"purchase_date\"])\n",
    "df[\"entry_id\"] = df[\"entry_id\"].astype(int)\n",
    "df[\"offer_ref\"] = df[\"offer_ref\"].astype(int)\n",
    "df[\"score\"] = df[\"score\"].astype(float)\n",
    "\n",
    "# Get Sentiment Cases based on score\n",
    "df[\"sentiment\"] = df[\"score\"].apply(lambda x: \"Positive\" if x >= 4 else \"Negative\" if x <= 2 else \"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only text and sentiment\n",
    "to_clean = df[[\"review_text\", \"sentiment\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>all_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_text, sentiment, has_emoji, all_emoji]\n",
       "Index: []"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1927 reviews containing special unicode characters\n",
    "to_clean[to_clean[\"review_text\"].str.contains(\"[\\t\\r\\n\\v\\f\\ufeff]\")].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of newlines and other whitespace chars\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].replace(\"[\\t\\r\\n\\v\\f\\ufeff]\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_text, sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove whitespaces created by previous step\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].replace(\" +\", \" \", regex=True)\n",
    "to_clean[to_clean[\"review_text\"].str.contains(\"  \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove cyrillic characters. Sometimes there are reviews half written in cyrillic and half in polish, so I will keep polish characters.\n",
    "cyrylic_regex = f\"[ {string.punctuation}0-9]*[\\u0400-\\u04FF]+[ {string.punctuation}0-9]*[\\u0400-\\u04FF]+[ {string.punctuation}0-9]*\"\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(lambda x: re.sub(cyrylic_regex, \"\", x)).replace(\"\", np.nan)\n",
    "to_clean = to_clean.dropna(subset=[\"review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "# pipe = pipeline(\"text-classification\", model=model_ckpt)\n",
    "# language_classification = pipe(to_clean[\"review_text\"].transform(lambda x: x[:100]).to_list(), top_k=1, truncation=True)\n",
    "# to_clean = pd.concat([to_clean.reset_index(), pd.DataFrame(np.array(language_classification).reshape(-1).tolist())], axis=1).set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lot of Wrong predictions. I will fix them manually\n",
    "# to_clean[(to_clean[\"label\"] != \"pl\")].iloc[2400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark all emojis in data. All_emoji will be excluded entirely, and has_emoji will remove only emojis.\n",
    "to_clean[\"has_emoji\"] = to_clean[\"review_text\"].transform(lambda x: np.any([emoji.is_emoji(c) for c in x]))\n",
    "to_clean[\"all_emoji\"] = to_clean[\"review_text\"].transform(lambda x: np.all([emoji.is_emoji(c) for c in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "# 460 Reviews containing emojis\n",
    "print(len(to_clean[to_clean[\"has_emoji\"]]))\n",
    "# 42 reviews containing only emojis\n",
    "print(len(to_clean[to_clean[\"all_emoji\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>all_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>😑😑</td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>😐</td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9421</th>\n",
       "      <td>👍</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053</th>\n",
       "      <td>👍👍👍👍👍</td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>🤗</td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11179</th>\n",
       "      <td>🥳🎉</td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13728</th>\n",
       "      <td>👍🏻👍🏻</td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14711</th>\n",
       "      <td>👍👍</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24204</th>\n",
       "      <td>🙂</td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25324</th>\n",
       "      <td>😫</td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_text sentiment  has_emoji  all_emoji\n",
       "0              😑😑  Negative       True       True\n",
       "1091            😐  Negative       True       True\n",
       "9421            👍   Neutral       True       True\n",
       "10053       👍👍👍👍👍  Positive       True       True\n",
       "10958           🤗  Positive       True       True\n",
       "11179          🥳🎉  Positive       True       True\n",
       "13728        👍🏻👍🏻  Negative       True       True\n",
       "14711          👍👍   Neutral       True       True\n",
       "24204           🙂  Positive       True       True\n",
       "25324           😫  Negative       True       True"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can sort of guess the sentiment of the review based on the emojis. But it's not consistent.\n",
    "to_clean[to_clean[\"all_emoji\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all reviews containing single repeating characters that are non-emoji\n",
    "to_clean = to_clean.loc[~(to_clean[\"review_text\"].transform(lambda x: len(set(x)) == 1) & ~to_clean[\"all_emoji\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6282/585859017.py:6: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  & ~to_clean[\"review_text\"].str.lower().str.contains(\"(ok|[0-9]|:[\\)\\(]|;[\\)\\()\\/]|\\*|bdb|kk|x)\"))\n"
     ]
    }
   ],
   "source": [
    "# remove reviews with only 3 unique characters that are not meaninful. Decided by hand.\n",
    "# Meaningfull list contains different versions of emoticons and ok and kk and bdb and x... and 5/5 etc.\n",
    "to_clean = to_clean[\n",
    "    ~(to_clean[\"review_text\"].transform(lambda x: len(set(x)) < 3) \n",
    "    & ~to_clean[\"has_emoji\"] \n",
    "    & ~to_clean[\"review_text\"].str.lower().str.contains(\"(ok|[0-9]|:[\\)\\(]|;[\\)\\()\\/]|\\*|bdb|kk|x)\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark Ok's in data.\n",
    "to_clean[\"has_ok\"] = to_clean[\"review_text\"].str.lower().str.contains(\"\\Wok\\W\")\n",
    "to_clean[to_clean[\"has_ok\"]] = to_clean[to_clean[\"has_ok\"]].replace(r\"\\bok\\b\", \"Ok\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kupiłem za namową sąsiadów, którzy zachwycali się możliwością pieczenia 2 potraw jednocześnie. Dual Cooki nie są drogie, miałem Ok. 2000 zł na piekarnik (poprzedni zepsuł się po 13 latach, ale wiem, że takich urządzeń już nie ma...). Zdecydowałem się na ten model choć już w sklepie pojawiły się pierwsze wątpliwości... drzwiczki piekarnika trzaskają jak w maluchu, obudowa drzwi jest w pełni plastikowa i nie znalazłem żadnego uszczelnienie tej przegrody rozdzielającej piekarnik na 2 części. Sprzedawca stwierdził, że są to bzdety nie mające wpływu na jakość pieczenia i szczerze mówiąc przekonał mnie. Piekę głównie mięsiwa, a żona ciasta - piekarnik działa praktycznie codziennie, używamy go także do podgrzewania (nie lubię mikrofali). Rozczarowanie przyszło już po pierwszym pieczeniu - piekarnik bardzo długo się nagrzewa - temperaturę 220 stopni osiągnął po 20 minutach, mimo, że termostat pokazywał taką temperaturę już po 8-10 minutach - własny termometr pokazał, że piekarnik przekłamuje... Potrawa upiekła się równomiernie, ale stanowczo za długo to trwało. Trzaskające drzwi piekarnika doprowadzają mnie do szału - po co producent zamontował 2 gumki amortyzujące, skoro są za krótkie? Na dodatek w moim starym piekarniku drzwi domykały się delikatnie, wyhamowując pod koniec. Plastikowość piekarnika faktycznie nie ma wpływu na użytkowanie. Kolejnym rozczarowaniem jest ta granatowa emalia ceramiczna - strasznie trudno ją doczyścić. Przy kolejnym pieczeniu zorientowałem się, że ten piekarnik ma tylko 4 poziomy, a nie jak mój poprzedni 5! Na dodatek rozmieszczenie poziomów przy pieczeniu dual cook nie pozwala na zmieszczenie w dolnej części niczego co nie jest płaskie, a w górnej nie mieści się brytfanna z małym wiejskim kurczakiem... Przegrodę po prostu wyjąłem z piekarnika - wychodzi na to, że dual cook to ściema marketingowa. Na dodatek korzystając z komory górnej mamy tylko grzałkę górną i termoobieg - brak grzałki dolnej - w przypadku dolnej komory nie mamy grzałki górnej i grilla - totalnie bez sensu. Kolejny problem pojawił się przy pieczeniu z parą (blacha z wodą pod mięsem) - uszczelka przecieka i woda skrapla się po szafce... W związku z powyższym sprzedałem piekarnik po miesiącu za połowę ceny na znanym portalu aukcyjnym i kupiłem coś normalnego od polskiego producenta za 1300 zł - piekarnik nagrzewa się do 220 stopni w 8 minut i nie przecieka przy pieczeniu na parze, no i ma delikatny domyk drzwi. Nigdy więcej badziewia Samsunga - tak jak przejechałem się na 2 flagowych telefonach tej marki i tanim tv, tak teraz jeszcze na piekarniku! AGD tej firmy to tragedia!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_clean[to_clean[\"has_ok\"] & (to_clean[\"sentiment\"] != \"Positive\")][\"review_text\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>all_emoji</th>\n",
       "      <th>has_ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_text, sentiment, has_emoji, all_emoji, has_ok]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix_ok_in_string assumes that ok. (circa) happens once per review. We can safely assume that.\n",
    "to_clean[to_clean[\"review_text\"].transform(lambda x: len(re.findall(r\"\\bok\\b.? [0-9]+\", x))) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function discriminates between ok meaning good and ok meaning circa \n",
    "# which is a short form of około in polish language.\n",
    "# Ok has it's own fix because it is very common in reviews and gives positive sentiment.\n",
    "def fix_ok_in_string(text):\n",
    "    circa_match = re.search(r\"\\bok\\b.? [0-9]+\", text.lower())\n",
    "    if circa_match is not None:\n",
    "        circa_match = circa_match.span()\n",
    "        return re.sub(r\"\\b(ok|Ok|OK|oK)\\b\", \"Ok\", text[:circa_match[0]]) + text[circa_match[0]:circa_match[1]] + re.sub(r\"\\b(ok|Ok|OK|oK)\\b\", \"Ok\", text[circa_match[1]:])\n",
    "    else:\n",
    "        return re.sub(r\"\\b(ok|Ok|OK|oK)\\b\", \"Ok\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok. lalala ok. 100kg Ok!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_ok_in_string(\"ok. lalala ok. 100kg ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all ok's in data.\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(fix_ok_in_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all numbers from data.\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(lambda x: re.sub(\"[0-9]+\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Largest default polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Autocorrect speller\n",
    "spell = Speller(\"pl\", only_replacements=True)\n",
    "\n",
    "# Enchant spellcheckers\n",
    "chkr = SpellChecker(\"pl_Pl\") \n",
    "d_typo = enchant.Dict(\"pl_PL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(lambda x: nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean[\"Typo Data\"] = (\n",
    "    to_clean[\"review_text\"].transform(lambda x: \n",
    "        [[token.text, \n",
    "          d_typo.suggest(token.text), \n",
    "          i, \n",
    "          str(x).find(token.text), \n",
    "          len(token.text)] \n",
    "        for i, token in enumerate(x) \n",
    "            if not token.is_punct \n",
    "               and (not d_typo.check(token.text)) \n",
    "               and (emoji.is_emoji(token.text) == False)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean.to_pickle(\"./data/typos_annotated.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will run 3 mins\n",
    "\n",
    "# Get subset of data.\n",
    "checker_test = to_clean[\"review_text\"].iloc[:2000].transform(lambda x: nlp(x))\n",
    "\n",
    "# 42% of first 2000 reviews contain typos\n",
    "# pyenchany seems good at detecting typos however it seems bad at fixing typos So we'll have to be careful with it.\n",
    "checker_test[checker_test.transform(lambda x: all([d_typo.check(token.text.lower()) for token in x if not token.is_punct])) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Mins. tokenize data\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes 44 mins.\n",
    "## Fix all typos. Write 2 csv files with and without type fixing. Used for comparison in another script.\n",
    "to_clean[\"review_text\"].transform(lambda x: [d_typo.suggest(token.text)[0] if (not token.is_punct) and (not d_typo.check(token.text)) and (chkr.suggest(token.text))  else token for token in x]).to_csv(\"Testing Typo Checking.csv\")\n",
    "to_clean[\"review_text\"].to_csv(\"Comparison to a Typo fix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've forgotten about sentiment.\n",
    "to_clean[\"sentiment\"].to_csv(\"sentiment provision.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
