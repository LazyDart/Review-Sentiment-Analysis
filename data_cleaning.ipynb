{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import emoji\n",
    "import spacy\n",
    "import re\n",
    "from autocorrect import Speller\n",
    "import enchant\n",
    "from enchant.checker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"review_text\" nan are to be deleted. Other can stay.\n",
    "df = df.dropna(subset=[\"review_text\"])\n",
    "\n",
    "# Remove invalid entries\n",
    "df = df.loc[df[\"entry_date\"] != \"entry_date\"]\n",
    "\n",
    "# Remove duplicate entries\n",
    "df = df.drop_duplicates([\"offer_ref\", \"entry_id\", \"review_text\"]).drop_duplicates(\"review_text\")\n",
    "\n",
    "# fix data types\n",
    "df[\"entry_date\"] = pd.to_datetime(df[\"entry_date\"])\n",
    "df[\"purchase_date\"] = pd.to_datetime(df[\"purchase_date\"])\n",
    "df[\"entry_id\"] = df[\"entry_id\"].astype(int)\n",
    "df[\"offer_ref\"] = df[\"offer_ref\"].astype(int)\n",
    "df[\"score\"] = df[\"score\"].astype(float)\n",
    "\n",
    "# Get Sentiment Cases based on score\n",
    "df[\"sentiment\"] = df[\"score\"].apply(lambda x: \"Positive\" if x >= 4 else \"Negative\" if x <= 2 else \"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean = df[[\"review_text\", \"sentiment\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of newlines\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].replace(\"[\\t\\r\\n\\v\\f\\ufeff]\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_text, sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove whitespaces\n",
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].replace(\" +\", \" \", regex=True)\n",
    "to_clean[to_clean[\"review_text\"].str.contains(\"  \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean[\"has_emoji\"] = to_clean[\"review_text\"].transform(lambda x: np.any([emoji.is_emoji(c) for c in x]))\n",
    "to_clean[\"all_emoji\"] = to_clean[\"review_text\"].transform(lambda x: np.all([emoji.is_emoji(c) for c in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# 460 Reviews containing emojis\n",
    "print(len(to_clean[to_clean[\"has_emoji\"]]))\n",
    "# 42 reviews containing only emojis\n",
    "print(len(to_clean[to_clean[\"all_emoji\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>all_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td></td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9417</th>\n",
       "      <td></td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10049</th>\n",
       "      <td></td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10954</th>\n",
       "      <td></td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11175</th>\n",
       "      <td>コ</td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13724</th>\n",
       "      <td>火</td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14707</th>\n",
       "      <td></td>\n",
       "      <td>Neutral</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24200</th>\n",
       "      <td></td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25320</th>\n",
       "      <td></td>\n",
       "      <td>Negative</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_text sentiment  has_emoji  all_emoji\n",
       "0                Negative       True       True\n",
       "1091              Negative       True       True\n",
       "9417               Neutral       True       True\n",
       "10049         Positive       True       True\n",
       "10954             Positive       True       True\n",
       "11175          コ  Positive       True       True\n",
       "13724        火  Negative       True       True\n",
       "14707             Neutral       True       True\n",
       "24200             Positive       True       True\n",
       "25320             Negative       True       True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can sort of guess the sentiment of the review based on the emojis. But it's not consistent.\n",
    "to_clean[to_clean[\"all_emoji\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>all_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_text, sentiment, has_emoji, all_emoji]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1927 reviews containing special unicode characters\n",
    "to_clean[to_clean[\"review_text\"].str.contains(\"[\\t\\r\\n\\v\\f\\ufeff]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean[\"has_ok\"] = to_clean[\"review_text\"].str.lower().str.contains(\"\\Wok\\W\")\n",
    "to_clean[to_clean[\"has_ok\"]] = to_clean[to_clean[\"has_ok\"]].replace(r\"\\bok\\b\", \"Ok\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kupiem za namow ssiad贸w, kt贸rzy zachwycali si mo偶liwoci pieczenia 2 potraw jednoczenie. Dual Cooki nie s drogie, miaem Ok. 2000 z na piekarnik (poprzedni zepsu si po 13 latach, ale wiem, 偶e takich urzdze ju偶 nie ma...). Zdecydowaem si na ten model cho ju偶 w sklepie pojawiy si pierwsze wtpliwoci... drzwiczki piekarnika trzaskaj jak w maluchu, obudowa drzwi jest w peni plastikowa i nie znalazem 偶adnego uszczelnienie tej przegrody rozdzielajcej piekarnik na 2 czci. Sprzedawca stwierdzi, 偶e s to bzdety nie majce wpywu na jako pieczenia i szczerze m贸wic przekona mnie. Piek g贸wnie misiwa, a 偶ona ciasta - piekarnik dziaa praktycznie codziennie, u偶ywamy go tak偶e do podgrzewania (nie lubi mikrofali). Rozczarowanie przyszo ju偶 po pierwszym pieczeniu - piekarnik bardzo dugo si nagrzewa - temperatur 220 stopni osign po 20 minutach, mimo, 偶e termostat pokazywa tak temperatur ju偶 po 8-10 minutach - wasny termometr pokaza, 偶e piekarnik przekamuje... Potrawa upieka si r贸wnomiernie, ale stanowczo za dugo to trwao. Trzaskajce drzwi piekarnika doprowadzaj mnie do szau - po co producent zamontowa 2 gumki amortyzujce, skoro s za kr贸tkie? Na dodatek w moim starym piekarniku drzwi domykay si delikatnie, wyhamowujc pod koniec. Plastikowo piekarnika faktycznie nie ma wpywu na u偶ytkowanie. Kolejnym rozczarowaniem jest ta granatowa emalia ceramiczna - strasznie trudno j doczyci. Przy kolejnym pieczeniu zorientowaem si, 偶e ten piekarnik ma tylko 4 poziomy, a nie jak m贸j poprzedni 5! Na dodatek rozmieszczenie poziom贸w przy pieczeniu dual cook nie pozwala na zmieszczenie w dolnej czci niczego co nie jest paskie, a w g贸rnej nie mieci si brytfanna z maym wiejskim kurczakiem... Przegrod po prostu wyjem z piekarnika - wychodzi na to, 偶e dual cook to ciema marketingowa. Na dodatek korzystajc z komory g贸rnej mamy tylko grzak g贸rn i termoobieg - brak grzaki dolnej - w przypadku dolnej komory nie mamy grzaki g贸rnej i grilla - totalnie bez sensu. Kolejny problem pojawi si przy pieczeniu z par (blacha z wod pod misem) - uszczelka przecieka i woda skrapla si po szafce... W zwizku z powy偶szym sprzedaem piekarnik po miesicu za poow ceny na znanym portalu aukcyjnym i kupiem co normalnego od polskiego producenta za 1300 z - piekarnik nagrzewa si do 220 stopni w 8 minut i nie przecieka przy pieczeniu na parze, no i ma delikatny domyk drzwi. Nigdy wicej badziewia Samsunga - tak jak przejechaem si na 2 flagowych telefonach tej marki i tanim tv, tak teraz jeszcze na piekarniku! AGD tej firmy to tragedia!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_clean[to_clean[\"has_ok\"] & (to_clean[\"sentiment\"] != \"Positive\")][\"review_text\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>all_emoji</th>\n",
       "      <th>has_ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_text, sentiment, has_emoji, all_emoji, has_ok]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix_ok_in_string assumes that ok. (circa) happens once per review. We can safely assume that.\n",
    "to_clean[to_clean[\"review_text\"].transform(lambda x: len(re.findall(r\"\\bok\\b.? [0-9]+\", x))) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function discriminates between ok meaning good and ok meaning circa \n",
    "# which is a short form of okoo in polish language.\n",
    "# Ok has it's own fix because it is very common in reviews and gives positive sentiment.\n",
    "def fix_ok_in_string(text):\n",
    "    circa_match = re.search(r\"\\bok\\b.? [0-9]+\", text.lower())\n",
    "    if circa_match is not None:\n",
    "        circa_match = circa_match.span()\n",
    "        return re.sub(r\"\\b(ok|Ok|OK|oK)\\b\", \"Ok\", text[:circa_match[0]]) + text[circa_match[0]:circa_match[1]] + re.sub(r\"\\b(ok|Ok|OK|oK)\\b\", \"Ok\", text[circa_match[1]:])\n",
    "    else:\n",
    "        return re.sub(r\"\\b(ok|Ok|OK|oK)\\b\", \"Ok\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok. lalala ok. 100kg Ok!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_ok_in_string(\"ok. lalala ok. 100kg ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(fix_ok_in_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(lambda x: re.sub(\"[0-9]+\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pl_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = Speller(\"pl\", only_replacements=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkr = SpellChecker(\"pl_Pl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_typo = enchant.Dict(\"pl_PL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker_test = to_clean[\"review_text\"].iloc[:2000].transform(lambda x: nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  (, )\n",
       "1       (Lekkie, i, jak, jeste, na, kuligu, to, szypk...\n",
       "9       (Niepeny, produkt, ,, wprowadzanie, w, bd, ...\n",
       "13      (Bosch, to, ju偶, nie, ta, sama, marka, ,, co, ...\n",
       "15      (PIEKARNIK, BARDZO, DODRZE, FUNKCJONUJE, ,, CI...\n",
       "                              ...                        \n",
       "3635    (nie, polecam, ,, po,  , latach, u偶ytkowania, ...\n",
       "3638    (Wyglada, Ok, i, tyle, ., Regulacja, temperatu...\n",
       "3650    (Urzdzenie, mam, ponad, rok, ., U偶ywane, g贸w...\n",
       "3658    (Jestem, z, tego, robota, zadowolona, ,, ale, ...\n",
       "3659    (Bateria, bardzo, praktyczna, w, u偶ytkowaniu, ...\n",
       "Name: review_text, Length: 818, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 42% of first 2000 reviews contain typos\n",
    "# pyenchany seems good at detecting typos however it seems bad at fixing typos So we'll have to be careful with it.\n",
    "checker_test[checker_test.transform(lambda x: all([d_typo.check(token.text.lower()) for token in x if not token.is_punct])) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lekkie,\n",
       " i,\n",
       " jak,\n",
       " jeste,\n",
       " na,\n",
       " kuligu,\n",
       " to,\n",
       " 'szypo',\n",
       " spadasz,\n",
       " 'sabe',\n",
       " sanki,\n",
       " .,\n",
       " NIE,\n",
       " POLECAM,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d_typo.suggest(token.text)[0] if (not d_typo.check(token.text)) and (not token.is_punct) else token for token in checker_test.iloc[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean[\"review_text\"] = to_clean[\"review_text\"].transform(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taker 44 mins.\n",
    "# to_clean[\"review_text\"].transform(lambda x: [d_typo.suggest(token.text)[0] if (not token.is_punct) and (not d_typo.check(token.text)) and (chkr.suggest(token.text))  else token for token in x]).to_csv(\"Testing Typo Checking.csv\")\n",
    "# to_clean[\"review_text\"].to_csv(\"Comparison to a Typo fix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean[\"sentiment\"].to_csv(\"sentiment provision.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = checker_test.transform(lambda x: [d_typo.suggest(token.text)[0] if (not token.is_punct) and (not d_typo.check(token.text)) and (chkr.suggest(token.text))  else token for token in x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
